{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.pyplot import subplots\n",
    "from statsmodels.api import OLS, add_constant\n",
    "import sklearn.model_selection as skm\n",
    "import sklearn.linear_model as skl\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from ISLP.models import (Stepwise, sklearn_selected, sklearn_selection_path)\n",
    "from l0bnb import fit_path\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.feature_selection import RFECV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8:\n",
    "\n",
    "(a) Generate random numbers for X and e\n",
    "\n",
    "(b) Generate response as polynomial degree 3 of X\n",
    "\n",
    "(c) Using stepwise selection, X, X_2, X_3, X_8, X_9 is selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-17.49765473   3.42680403  11.53035803  -2.52436037   9.81320787]\n",
      "[27.06849839  6.28132709  9.07969446  5.03825754  6.51117948]\n",
      "[-5040.481807709409, 62.692028388329256, 1687.5105788746287, -6.1999295828459005, 1058.6260184729974]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "X = np.random.normal(loc=0, scale=10, size=100)\n",
    "\n",
    "np.random.seed(101)\n",
    "e = np.random.normal(loc=0, scale=10, size=100)\n",
    "\n",
    "print(X[:5])\n",
    "print(e[:5])\n",
    "\n",
    "beta_0, beta_1, beta_2, beta_3 = 1, 1, 1, 1\n",
    "y = [beta_0 + beta_1 * (X[i] ** 1) + beta_2 * (X[i] ** 2) + beta_3 * (X[i] ** 3) + e[i] for i in range(len(X))]\n",
    "\n",
    "print(y[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>X</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>X_5</th>\n",
       "      <th>X_6</th>\n",
       "      <th>X_7</th>\n",
       "      <th>X_8</th>\n",
       "      <th>X_9</th>\n",
       "      <th>X_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-17.497655</td>\n",
       "      <td>306.167921</td>\n",
       "      <td>-5357.220572</td>\n",
       "      <td>93738.795892</td>\n",
       "      <td>-1.640209e+06</td>\n",
       "      <td>2.869981e+07</td>\n",
       "      <td>-5.021794e+08</td>\n",
       "      <td>8.786962e+09</td>\n",
       "      <td>-1.537512e+11</td>\n",
       "      <td>2.690286e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.426804</td>\n",
       "      <td>11.742986</td>\n",
       "      <td>40.240911</td>\n",
       "      <td>137.897717</td>\n",
       "      <td>4.725485e+02</td>\n",
       "      <td>1.619331e+03</td>\n",
       "      <td>5.549130e+03</td>\n",
       "      <td>1.901578e+04</td>\n",
       "      <td>6.516335e+04</td>\n",
       "      <td>2.233020e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.530358</td>\n",
       "      <td>132.949156</td>\n",
       "      <td>1532.951370</td>\n",
       "      <td>17675.478134</td>\n",
       "      <td>2.038046e+05</td>\n",
       "      <td>2.349940e+06</td>\n",
       "      <td>2.709565e+07</td>\n",
       "      <td>3.124225e+08</td>\n",
       "      <td>3.602344e+09</td>\n",
       "      <td>4.153631e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.524360</td>\n",
       "      <td>6.372395</td>\n",
       "      <td>-16.086222</td>\n",
       "      <td>40.607421</td>\n",
       "      <td>-1.025078e+02</td>\n",
       "      <td>2.587665e+02</td>\n",
       "      <td>-6.532200e+02</td>\n",
       "      <td>1.648963e+03</td>\n",
       "      <td>-4.162576e+03</td>\n",
       "      <td>1.050784e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.813208</td>\n",
       "      <td>96.299049</td>\n",
       "      <td>945.002582</td>\n",
       "      <td>9273.506779</td>\n",
       "      <td>9.100285e+04</td>\n",
       "      <td>8.930299e+05</td>\n",
       "      <td>8.763488e+06</td>\n",
       "      <td>8.599793e+07</td>\n",
       "      <td>8.439155e+08</td>\n",
       "      <td>8.281519e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   const          X         X_2          X_3           X_4           X_5  \\\n",
       "0    1.0 -17.497655  306.167921 -5357.220572  93738.795892 -1.640209e+06   \n",
       "1    1.0   3.426804   11.742986    40.240911    137.897717  4.725485e+02   \n",
       "2    1.0  11.530358  132.949156  1532.951370  17675.478134  2.038046e+05   \n",
       "3    1.0  -2.524360    6.372395   -16.086222     40.607421 -1.025078e+02   \n",
       "4    1.0   9.813208   96.299049   945.002582   9273.506779  9.100285e+04   \n",
       "\n",
       "            X_6           X_7           X_8           X_9          X_10  \n",
       "0  2.869981e+07 -5.021794e+08  8.786962e+09 -1.537512e+11  2.690286e+12  \n",
       "1  1.619331e+03  5.549130e+03  1.901578e+04  6.516335e+04  2.233020e+05  \n",
       "2  2.349940e+06  2.709565e+07  3.124225e+08  3.602344e+09  4.153631e+10  \n",
       "3  2.587665e+02 -6.532200e+02  1.648963e+03 -4.162576e+03  1.050784e+04  \n",
       "4  8.930299e+05  8.763488e+06  8.599793e+07  8.439155e+08  8.281519e+09  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'X': X})\n",
    "for i in range(2, 11):\n",
    "    df[f'X_{i}'] = df['X'] ** i\n",
    "\n",
    "df = add_constant(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>6.296e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 28 Jul 2024</td> <th>  Prob (F-statistic):</th> <td>3.14e-211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:49:37</td>     <th>  Log-Likelihood:    </th> <td> -370.08</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   762.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    89</td>      <th>  BIC:               </th> <td>   790.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    1.0406</td> <td>    2.323</td> <td>    0.448</td> <td> 0.655</td> <td>   -3.576</td> <td>    5.657</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X</th>     <td>    1.2579</td> <td>    0.726</td> <td>    1.734</td> <td> 0.086</td> <td>   -0.184</td> <td>    2.699</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_2</th>   <td>    0.9378</td> <td>    0.167</td> <td>    5.608</td> <td> 0.000</td> <td>    0.605</td> <td>    1.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_3</th>   <td>    0.9924</td> <td>    0.021</td> <td>   47.252</td> <td> 0.000</td> <td>    0.951</td> <td>    1.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_4</th>   <td>    0.0015</td> <td>    0.003</td> <td>    0.476</td> <td> 0.635</td> <td>   -0.005</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_5</th>   <td> 8.106e-05</td> <td>    0.000</td> <td>    0.437</td> <td> 0.663</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_6</th>   <td>-6.806e-06</td> <td> 2.07e-05</td> <td>   -0.329</td> <td> 0.743</td> <td>-4.79e-05</td> <td> 3.43e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_7</th>   <td>-3.203e-07</td> <td> 6.21e-07</td> <td>   -0.516</td> <td> 0.607</td> <td>-1.55e-06</td> <td> 9.13e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_8</th>   <td> 9.868e-09</td> <td> 5.67e-08</td> <td>    0.174</td> <td> 0.862</td> <td>-1.03e-07</td> <td> 1.23e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_9</th>   <td> 3.965e-10</td> <td> 6.98e-10</td> <td>    0.568</td> <td> 0.571</td> <td> -9.9e-10</td> <td> 1.78e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_10</th>  <td>-1.624e-12</td> <td> 5.33e-11</td> <td>   -0.030</td> <td> 0.976</td> <td>-1.07e-10</td> <td> 1.04e-10</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.238</td> <th>  Durbin-Watson:     </th> <td>   2.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.538</td> <th>  Jarque-Bera (JB):  </th> <td>   1.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.188</td> <th>  Prob(JB):          </th> <td>   0.529</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.594</td> <th>  Cond. No.          </th> <td>2.06e+13</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.06e+13. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     1.000   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     1.000   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } & 6.296e+05   \\\\\n",
       "\\textbf{Date:}             & Sun, 28 Jul 2024 & \\textbf{  Prob (F-statistic):} & 3.14e-211   \\\\\n",
       "\\textbf{Time:}             &     16:49:37     & \\textbf{  Log-Likelihood:    } &   -370.08   \\\\\n",
       "\\textbf{No. Observations:} &         100      & \\textbf{  AIC:               } &     762.2   \\\\\n",
       "\\textbf{Df Residuals:}     &          89      & \\textbf{  BIC:               } &     790.8   \\\\\n",
       "\\textbf{Df Model:}         &          10      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       1.0406  &        2.323     &     0.448  &         0.655        &       -3.576    &        5.657     \\\\\n",
       "\\textbf{X}     &       1.2579  &        0.726     &     1.734  &         0.086        &       -0.184    &        2.699     \\\\\n",
       "\\textbf{X\\_2}  &       0.9378  &        0.167     &     5.608  &         0.000        &        0.605    &        1.270     \\\\\n",
       "\\textbf{X\\_3}  &       0.9924  &        0.021     &    47.252  &         0.000        &        0.951    &        1.034     \\\\\n",
       "\\textbf{X\\_4}  &       0.0015  &        0.003     &     0.476  &         0.635        &       -0.005    &        0.008     \\\\\n",
       "\\textbf{X\\_5}  &    8.106e-05  &        0.000     &     0.437  &         0.663        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{X\\_6}  &   -6.806e-06  &     2.07e-05     &    -0.329  &         0.743        &    -4.79e-05    &     3.43e-05     \\\\\n",
       "\\textbf{X\\_7}  &   -3.203e-07  &     6.21e-07     &    -0.516  &         0.607        &    -1.55e-06    &     9.13e-07     \\\\\n",
       "\\textbf{X\\_8}  &    9.868e-09  &     5.67e-08     &     0.174  &         0.862        &    -1.03e-07    &     1.23e-07     \\\\\n",
       "\\textbf{X\\_9}  &    3.965e-10  &     6.98e-10     &     0.568  &         0.571        &     -9.9e-10    &     1.78e-09     \\\\\n",
       "\\textbf{X\\_10} &   -1.624e-12  &     5.33e-11     &    -0.030  &         0.976        &    -1.07e-10    &     1.04e-10     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  1.238 & \\textbf{  Durbin-Watson:     } &    2.123  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.538 & \\textbf{  Jarque-Bera (JB):  } &    1.275  \\\\\n",
       "\\textbf{Skew:}          &  0.188 & \\textbf{  Prob(JB):          } &    0.529  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.594 & \\textbf{  Cond. No.          } & 2.06e+13  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.06e+13. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 6.296e+05\n",
       "Date:                Sun, 28 Jul 2024   Prob (F-statistic):          3.14e-211\n",
       "Time:                        16:49:37   Log-Likelihood:                -370.08\n",
       "No. Observations:                 100   AIC:                             762.2\n",
       "Df Residuals:                      89   BIC:                             790.8\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          1.0406      2.323      0.448      0.655      -3.576       5.657\n",
       "X              1.2579      0.726      1.734      0.086      -0.184       2.699\n",
       "X_2            0.9378      0.167      5.608      0.000       0.605       1.270\n",
       "X_3            0.9924      0.021     47.252      0.000       0.951       1.034\n",
       "X_4            0.0015      0.003      0.476      0.635      -0.005       0.008\n",
       "X_5         8.106e-05      0.000      0.437      0.663      -0.000       0.000\n",
       "X_6        -6.806e-06   2.07e-05     -0.329      0.743   -4.79e-05    3.43e-05\n",
       "X_7        -3.203e-07   6.21e-07     -0.516      0.607   -1.55e-06    9.13e-07\n",
       "X_8         9.868e-09   5.67e-08      0.174      0.862   -1.03e-07    1.23e-07\n",
       "X_9         3.965e-10   6.98e-10      0.568      0.571    -9.9e-10    1.78e-09\n",
       "X_10       -1.624e-12   5.33e-11     -0.030      0.976   -1.07e-10    1.04e-10\n",
       "==============================================================================\n",
       "Omnibus:                        1.238   Durbin-Watson:                   2.123\n",
       "Prob(Omnibus):                  0.538   Jarque-Bera (JB):                1.275\n",
       "Skew:                           0.188   Prob(JB):                        0.529\n",
       "Kurtosis:                       2.594   Cond. No.                     2.06e+13\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.06e+13. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OLS(y, df)\n",
    "result = model.fit()\n",
    "ols = result.predict(df)\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.93444674889668"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = result.predict(df)\n",
    "((pred - y)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('X', 'X_2', 'X_3', 'X_8', 'X_9')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs = SequentialFeatureSelector(\n",
    "    skl.LinearRegression(),\n",
    "    k_features=5,\n",
    "    forward=True,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=None\n",
    "    )\n",
    "selected_features = sfs.fit(df, y)\n",
    "selected_features.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['X', 'X_2', 'X_3', 'X_4', 'X_5'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "model = skl.LinearRegression()\n",
    "cv = skm.KFold(n_splits=5)\n",
    "\n",
    "rfecv = RFECV(estimator=model, step=1, scoring='neg_mean_squared_error', cv=cv)\n",
    "rfecv.fit(df, y)\n",
    "\n",
    "selected_features = rfecv.support_\n",
    "selected_feature_names = df.columns[selected_features]\n",
    "print(selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000000e+00  9.67330495e-01  8.75176067e-01  9.92354449e-01\n",
      "  1.40825774e-03  5.33420769e-05 -3.06346447e-06 -8.97609147e-08\n",
      " -9.89483350e-10  2.48569405e-11  3.82761110e-12]\n",
      "Best alpha: 10.0\n",
      "Test MSE: 108.709\n"
     ]
    }
   ],
   "source": [
    "lasso = skl.Lasso()\n",
    "\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "\n",
    "grid_search = skm.GridSearchCV(lasso, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(df, y)\n",
    "\n",
    "best_lasso = grid_search.best_estimator_\n",
    "best_lasso.fit(df, y)\n",
    "\n",
    "y_pred = best_lasso.predict(df)\n",
    "test_mse = mean_squared_error(y, y_pred)\n",
    "\n",
    "print(best_lasso.coef_)\n",
    "print(f'Best alpha: {grid_search.best_params_[\"alpha\"]}')\n",
    "print(f'Test MSE: {test_mse:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9:\n",
    "\n",
    "(a) Split the data into train and test set\n",
    "\n",
    "(b) Fit linear regression on train set and test error: 1492433\n",
    "\n",
    "(c) Ridge regression cross-validation and test error: 1478572 (alpha=10)\n",
    "\n",
    "(d) Lasso regression cross-validation and test error: 1477249 (alpha=10)\n",
    "\n",
    "(e) PCR regression cross-validation and test error: 1492443 (components=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Private  Apps  Accept  Enroll  Top10perc  Top25perc  F.Undergrad  \\\n",
       "0     Yes  1660    1232     721         23         52         2885   \n",
       "1     Yes  2186    1924     512         16         29         2683   \n",
       "2     Yes  1428    1097     336         22         50         1036   \n",
       "3     Yes   417     349     137         60         89          510   \n",
       "4     Yes   193     146      55         16         44          249   \n",
       "\n",
       "   P.Undergrad  Outstate  Room.Board  Books  Personal  PhD  Terminal  \\\n",
       "0          537      7440        3300    450      2200   70        78   \n",
       "1         1227     12280        6450    750      1500   29        30   \n",
       "2           99     11250        3750    400      1165   53        66   \n",
       "3           63     12960        5450    450       875   92        97   \n",
       "4          869      7560        4120    800      1500   76        72   \n",
       "\n",
       "   S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "0       18.1           12    7041         60  \n",
       "1       12.2           16   10527         56  \n",
       "2       12.9           30    8735         54  \n",
       "3        7.7           37   19016         59  \n",
       "4       11.9            2   10922         15  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "College = load_data('College')\n",
    "College.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1492443.379039793"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = College.drop(columns='Apps')\n",
    "X['Private'] = X['Private'].map({'No': 0, 'Yes': 1})\n",
    "X = add_constant(X)\n",
    "y = College['Apps']\n",
    "\n",
    "X_train, X_test, y_train, y_test = skm.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = OLS(y_train, X_train).fit()\n",
    "pred = model.predict(X_test)\n",
    "((pred - y_test)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   Apps   R-squared:                       0.935\n",
      "Model:                            OLS   Adj. R-squared:                  0.934\n",
      "Method:                 Least Squares   F-statistic:                     514.4\n",
      "Date:                Sun, 28 Jul 2024   Prob (F-statistic):               0.00\n",
      "Time:                        15:51:43   Log-Likelihood:                -5167.8\n",
      "No. Observations:                 621   AIC:                         1.037e+04\n",
      "Df Residuals:                     603   BIC:                         1.045e+04\n",
      "Df Model:                          17                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const         -58.9802    439.540     -0.134      0.893    -922.196     804.235\n",
      "Private      -651.6070    149.913     -4.347      0.000    -946.022    -357.192\n",
      "Accept          1.6656      0.044     38.271      0.000       1.580       1.751\n",
      "Enroll         -1.0306      0.206     -5.007      0.000      -1.435      -0.626\n",
      "Top10perc      51.7066      5.896      8.769      0.000      40.127      63.287\n",
      "Top25perc     -14.9924      4.770     -3.143      0.002     -24.361      -5.624\n",
      "F.Undergrad     0.0565      0.036      1.570      0.117      -0.014       0.127\n",
      "P.Undergrad    -0.0263      0.044     -0.602      0.547      -0.112       0.059\n",
      "Outstate       -0.0712      0.020     -3.507      0.000      -0.111      -0.031\n",
      "Room.Board      0.1577      0.052      3.036      0.002       0.056       0.260\n",
      "Books           0.1129      0.262      0.431      0.667      -0.402       0.628\n",
      "Personal        0.0388      0.070      0.551      0.582      -0.099       0.177\n",
      "PhD           -10.4225      5.030     -2.072      0.039     -20.301      -0.544\n",
      "Terminal       -1.4063      5.428     -0.259      0.796     -12.067       9.254\n",
      "S.F.Ratio       4.9444     13.994      0.353      0.724     -22.538      32.427\n",
      "perc.alumni    -0.5175      4.475     -0.116      0.908      -9.306       8.271\n",
      "Expend          0.0411      0.013      3.163      0.002       0.016       0.067\n",
      "Grad.Rate       8.5633      3.083      2.778      0.006       2.508      14.618\n",
      "==============================================================================\n",
      "Omnibus:                      380.022   Durbin-Watson:                   1.767\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             8077.404\n",
      "Skew:                           2.301   Prob(JB):                         0.00\n",
      "Kurtosis:                      20.058   Cond. No.                     1.81e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.81e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 10.0\n",
      "Test MSE: 1478572.811\n"
     ]
    }
   ],
   "source": [
    "ridge = skl.Ridge()\n",
    "param_grid = {'alpha': [0.1, 1.0, 10.0, 100.0]}\n",
    "\n",
    "grid_search = skm.GridSearchCV(ridge, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_ridge = grid_search.best_estimator_\n",
    "best_ridge.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_ridge.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Best alpha: {grid_search.best_params_[\"alpha\"]}')\n",
    "print(f'Test MSE: {test_mse:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 10.0\n",
      "Test MSE: 1477249.003\n"
     ]
    }
   ],
   "source": [
    "lasso = skl.Lasso()\n",
    "\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "\n",
    "grid_search = skm.GridSearchCV(lasso, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_lasso = grid_search.best_estimator_\n",
    "best_lasso.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_lasso.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Best alpha: {grid_search.best_params_[\"alpha\"]}')\n",
    "print(f'Test MSE: {test_mse:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of components: 18\n",
      "Test MSE: 1492443.379\n"
     ]
    }
   ],
   "source": [
    "def create_pipeline(n_components):\n",
    "    return Pipeline([\n",
    "        ('pca', PCA(n_components=n_components)),\n",
    "        ('regression', skl.LinearRegression())\n",
    "    ])\n",
    "\n",
    "n_components_range = range(1, X_train.shape[1] + 1)\n",
    "\n",
    "best_n_components = None\n",
    "best_score = float('inf')\n",
    "\n",
    "for n_components in n_components_range:\n",
    "    pipeline = create_pipeline(n_components)\n",
    "    scores = skm.cross_val_score(pipeline, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    mean_score = -np.mean(scores)\n",
    "    \n",
    "    if mean_score < best_score:\n",
    "        best_score = mean_score\n",
    "        best_n_components = n_components\n",
    "\n",
    "best_pipeline = create_pipeline(best_n_components)\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Best number of components: {best_n_components}')\n",
    "print(f'Test MSE: {test_mse:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
